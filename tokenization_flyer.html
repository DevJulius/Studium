<!DOCTYPE html>
<html lang="de">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LLM Tokenisierung Erklärt</title>
    <link rel="stylesheet" href="tokenization_style.css"> <!-- CSS-Dateiname aktualisiert -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&display=swap" rel="stylesheet">
</head>
<body>

    <!-- Wrapper bleibt für die Gesamtzentrierung -->
    <div class="page-wrapper">

        <!-- Flyer Container -->
        <div class="flyer-container">

            <!-- Kontakt-Header JETZT INNERHALB des Flyers -->
            <div class="contact-header">
                <p class="contact-number">-- <br> --</p> <!-- << HIER IHREN NAMEN EINTRAGEN -->
            </div>

            <!-- Top Section -->
            <div class="flyer-section top-section">
                <h1>Wie funktioniert Tokenisierung?</h1>
                <h2>Verständnis für Tokenisierung in Bezug auf LLMs</h2>
            </div>

            <!-- Middle Section (What/Why) -->
            <div class="flyer-section middle-section">
                <div class="info-block">
                    <img src="icon-lupe.svg" alt="Aufteilen Icon" class="icon">
                    <h3>Was ist es?</h3>
                    <p>Aufteilung von Text in kleinere Teile, genannt <strong>Tokens</strong>.</p>
                </div>
                <div class="info-block">
                     <img src="icon-chip.svg" alt="Verarbeiten Icon" class="icon">
                    <h3>Warum?</h3>
                    <p>Computer brauchen <strong>Nummern</strong>, keine Wörter, um Sprachen zu verarbeiten.</p>
                </div>
            </div>

            <!-- Central Visual -->
            <div class="flyer-section central-visual">
                <h3>So funktioniert es:</h3>
                <p class="flow-description">Text → Tokens → Nummern IDs</p>
                <code class="code-block input-text">"Hallo Chatbot!"</code>
                <div class="arrow">↓</div>
                <div class="token-display">
                    <span class="token-box">Hallo</span>
                    <span class="token-box">Chat</span>
                    <span class="token-box">bot</span>
                    <span class="token-box">!</span>
                </div>
                <div class="arrow">↓</div>
                <p class="note">(Verwendung eines Vokabulars/Wörterbuchs)</p>
                <code class="code-block output-ids">[ 87 ] [ 1234 ] [ 567 ] [ 9 ]</code>
                <p class="note">(Beispiel-IDs - Die tatsächlichen Zahlen variieren je nach Modell)</p>
            </div>

            <!-- Bottom Section -->
            <div class="flyer-section bottom-section">
                <h3>Warum ist es wichtig?</h3>
                <p class="takeaway">Tokenisierung ist der <strong>erste entscheidende Schritt</strong> für LLMs, um Kontext zu verstehen, Muster zu lernen und Text zu erzeugen.</p>
            </div>

        </div> <!-- Ende flyer-container -->

        <!-- In-Depth Section -->
        <div class="in-depth-info"> <!-- Neuer Container für die Kurzfassung -->
            <h2>Tokenisierung: Wichtige Details</h2>
        
            <h3>Wie wird zerlegt? (Arten)</h3>
            <ul>
                <li><strong>Wort-basiert:</strong> Trennt bei Leerzeichen/Satzzeichen. Einfach, aber Probleme bei unbekannten Wörtern. (<code>"Hallo", "!"</code>)</li>
                <li><strong>Zeichen-basiert:</strong> Trennt in einzelne Buchstaben/Zeichen. Erkennt alles, aber erzeugt sehr lange Sequenzen. (<code>"H", "a", "l", "l", "o"</code>)</li>
                <li><strong>Subword-basiert (häufig):</strong> Kompromiss. Häufige Wörter bleiben ganz, seltene werden zerlegt. Gut für unbekannte Wörter & Vokabulargröße. (<code>"Chat", "bot"</code>)</li>
            </ul>
        
            <h3>Vokabular & IDs</h3>
            <p>Ein festes "Wörterbuch" (Vokabular) weist jedem möglichen Token eine eindeutige Zahl (ID) zu. Das Modell arbeitet mit diesen IDs. Subwords helfen sehr gut bei Wörtern, die nicht im Vokabular stehen.</p>
        
            <h3>Auswirkungen</h3>
            <p>Die Art der Tokenisierung beeinflusst stark:</p>
            <ul>
                <li><strong>Verständnis:</strong> Wie gut das Modell Wörter (auch seltene/neue) versteht.</li>
                <li><strong>Effizienz & Kosten:</strong> Die Anzahl der Tokens bestimmt Rechenaufwand und oft API-Kosten.</li>
                <li><strong>Mehrsprachigkeit:</strong> Wichtig für Sprachen mit vielen Wortformen.</li>
            </ul>
        
            <h3>Spezielle Tokens</h3>
            <p>Modelle nutzen oft spezielle Marker für Struktur und Steuerung, z.B.:</p>
            <ul>
                <li><code>[SEP]</code>: Trennt Textabschnitte.</li>
                <li><code>[PAD]</code>: Füllt kurze Sätze auf eine feste Länge.</li>
                <li><code>[UNK]</code>: Markiert (selten nötig bei Subwords) unbekannte Wörter.</li>
            </ul>
        </div>

</body>
</html>
